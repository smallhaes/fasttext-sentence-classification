{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using a Trained  FastText Model for Batch Inference\n",
    "\n",
    "In this notebook, we will demonstrate how to make predictions on large quantities of data asynchronously using the ML pipelines with Azure Machine Learning. Batch inference (or batch scoring) provides cost-effective inference, with unparalleled throughput for asynchronous applications. Batch prediction pipelines can scale to perform inference on terabytes of production data. Batch prediction is optimized for high throughput, fire-and-forget predictions for a large collection of data.\n",
    "\n",
    "> **Tip**\n",
    "The dataset we use is not that huge. We aim to make you know the workflow of batch inference. If your system requires low-latency processing (to process a single document or small set of documents quickly), please use realtime inference. Refer to fasttext_realtime_inference.ipynb for more details. \n",
    "\n",
    "The outline of this notebook is as follows:\n",
    "\n",
    "- Create a DataStore referencing documents stored in a blob container.\n",
    "- Reference a trained fastText model from a complete experiment.\n",
    "- Use the fastText model to do batch inference on the documents in the data blob container.\n",
    "\n",
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first. This sets you up with a working config file that has information on your workspace, subscription id, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azureml.core import Workspace, Dataset, Datastore, Run\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.pipeline.wrapper import PipelineRun, Module, dsl\n",
    "from azureml.pipeline.wrapper._pipeline_endpoint import PipelineEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "Create a workspace object from the existing workspace. Workspace.from_config() reads the file config.json and loads the details into an object named workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DesignerDRI_EASTUS\n",
      "DesignerDRI\n",
      "eastus\n",
      "74eccef0-4b8d-4f83-b5f9-fa100d155b22\n",
      "dict_keys(['attached-aks', 'default', 'compute', 'aml-compute', 'aml-compute-gpu'])\n"
     ]
    }
   ],
   "source": [
    "workspace = Workspace.from_config('config.json')\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id,\n",
    "      workspace.compute_targets.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach existing compute resource\n",
    "By using Azure Machine Learning Compute, a managed service, data scientists can train machine learning models on clusters of Azure virtual machines. Examples include VMs with GPU support. In this tutorial, you create Azure Machine Learning Compute as your training environment. The code below creates the compute clusters for you if they don't already exist in your workspace.\n",
    "\n",
    "**Creation of compute takes approximately 5 minutes. If the AmlCompute with that name is already in your workspace the code will skip the creation process.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: aml-compute\n"
     ]
    }
   ],
   "source": [
    "aml_compute_name = 'aml-compute'\n",
    "if aml_compute_name in workspace.compute_targets:\n",
    "    aml_compute = AmlCompute(workspace, aml_compute_name)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_name))\n",
    "else:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", min_nodes=1, max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace, aml_compute_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataset onto a blob container and register it to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading data/data_for_batch_inference/0\n",
      "Uploading data/data_for_batch_inference/1\n",
      "Uploading data/data_for_batch_inference/10\n",
      "Uploading data/data_for_batch_inference/11\n",
      "Uploading data/data_for_batch_inference/12\n",
      "Uploading data/data_for_batch_inference/13\n",
      "Uploading data/data_for_batch_inference/14\n",
      "Uploading data/data_for_batch_inference/15\n",
      "Uploading data/data_for_batch_inference/16\n",
      "Uploading data/data_for_batch_inference/17\n",
      "Uploading data/data_for_batch_inference/18\n",
      "Uploading data/data_for_batch_inference/19\n",
      "Uploading data/data_for_batch_inference/2\n",
      "Uploading data/data_for_batch_inference/20\n",
      "Uploading data/data_for_batch_inference/21\n",
      "Uploading data/data_for_batch_inference/22\n",
      "Uploading data/data_for_batch_inference/23\n",
      "Uploading data/data_for_batch_inference/24\n",
      "Uploading data/data_for_batch_inference/25\n",
      "Uploading data/data_for_batch_inference/26\n",
      "Uploading data/data_for_batch_inference/27\n",
      "Uploading data/data_for_batch_inference/28\n",
      "Uploading data/data_for_batch_inference/29\n",
      "Uploading data/data_for_batch_inference/3\n",
      "Uploading data/data_for_batch_inference/30\n",
      "Uploading data/data_for_batch_inference/31\n",
      "Uploading data/data_for_batch_inference/32\n",
      "Uploading data/data_for_batch_inference/33\n",
      "Uploading data/data_for_batch_inference/34\n",
      "Uploading data/data_for_batch_inference/35\n",
      "Uploading data/data_for_batch_inference/36\n",
      "Uploading data/data_for_batch_inference/37\n",
      "Uploaded data/data_for_batch_inference/0, 1 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/38\n",
      "Uploaded data/data_for_batch_inference/1, 2 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/39\n",
      "Uploaded data/data_for_batch_inference/10, 3 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/4\n",
      "Uploaded data/data_for_batch_inference/11, 4 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/40\n",
      "Uploaded data/data_for_batch_inference/12, 5 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/41\n",
      "Uploaded data/data_for_batch_inference/13, 6 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/42\n",
      "Uploaded data/data_for_batch_inference/14, 7 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/43\n",
      "Uploaded data/data_for_batch_inference/15, 8 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/44\n",
      "Uploaded data/data_for_batch_inference/16, 9 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/45\n",
      "Uploaded data/data_for_batch_inference/17, 10 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/46\n",
      "Uploaded data/data_for_batch_inference/18, 11 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/47\n",
      "Uploaded data/data_for_batch_inference/19, 12 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/48\n",
      "Uploaded data/data_for_batch_inference/2, 13 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/49\n",
      "Uploaded data/data_for_batch_inference/20, 14 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/5\n",
      "Uploaded data/data_for_batch_inference/21, 15 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/50\n",
      "Uploaded data/data_for_batch_inference/22, 16 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/51\n",
      "Uploaded data/data_for_batch_inference/23, 17 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/52\n",
      "Uploaded data/data_for_batch_inference/24, 18 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/53\n",
      "Uploaded data/data_for_batch_inference/25, 19 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/54\n",
      "Uploaded data/data_for_batch_inference/26, 20 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/55\n",
      "Uploaded data/data_for_batch_inference/27, 21 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/56\n",
      "Uploaded data/data_for_batch_inference/28, 22 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/57\n",
      "Uploaded data/data_for_batch_inference/29, 23 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/58\n",
      "Uploaded data/data_for_batch_inference/3, 24 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/59\n",
      "Uploaded data/data_for_batch_inference/30, 25 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/6\n",
      "Uploaded data/data_for_batch_inference/31, 26 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/60\n",
      "Uploaded data/data_for_batch_inference/32, 27 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/61\n",
      "Uploaded data/data_for_batch_inference/33, 28 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/62\n",
      "Uploaded data/data_for_batch_inference/34, 29 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/63\n",
      "Uploaded data/data_for_batch_inference/35, 30 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/64\n",
      "Uploaded data/data_for_batch_inference/36, 31 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/65\n",
      "Uploaded data/data_for_batch_inference/37, 32 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/66\n",
      "Uploaded data/data_for_batch_inference/38, 33 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/67\n",
      "Uploaded data/data_for_batch_inference/39, 34 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/68\n",
      "Uploaded data/data_for_batch_inference/4, 35 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/69\n",
      "Uploaded data/data_for_batch_inference/40, 36 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/7\n",
      "Uploaded data/data_for_batch_inference/41, 37 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/70\n",
      "Uploaded data/data_for_batch_inference/42, 38 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/71\n",
      "Uploaded data/data_for_batch_inference/43, 39 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/72\n",
      "Uploaded data/data_for_batch_inference/44, 40 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/73\n",
      "Uploaded data/data_for_batch_inference/45, 41 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/74\n",
      "Uploaded data/data_for_batch_inference/46, 42 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/75\n",
      "Uploaded data/data_for_batch_inference/47, 43 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/76\n",
      "Uploaded data/data_for_batch_inference/48, 44 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/77\n",
      "Uploaded data/data_for_batch_inference/49, 45 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/78\n",
      "Uploaded data/data_for_batch_inference/5, 46 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/79\n",
      "Uploaded data/data_for_batch_inference/50, 47 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/8\n",
      "Uploaded data/data_for_batch_inference/51, 48 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/80\n",
      "Uploaded data/data_for_batch_inference/52, 49 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/81\n",
      "Uploaded data/data_for_batch_inference/53, 50 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/82\n",
      "Uploaded data/data_for_batch_inference/54, 51 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/83\n",
      "Uploaded data/data_for_batch_inference/55, 52 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/84\n",
      "Uploaded data/data_for_batch_inference/56, 53 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/85\n",
      "Uploaded data/data_for_batch_inference/57, 54 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data/data_for_batch_inference/58, 55 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/87\n",
      "Uploaded data/data_for_batch_inference/59, 56 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/88\n",
      "Uploaded data/data_for_batch_inference/6, 57 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/89\n",
      "Uploaded data/data_for_batch_inference/60, 58 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/9\n",
      "Uploaded data/data_for_batch_inference/61, 59 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/90\n",
      "Uploaded data/data_for_batch_inference/62, 60 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/91\n",
      "Uploaded data/data_for_batch_inference/63, 61 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/92\n",
      "Uploaded data/data_for_batch_inference/64, 62 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/93\n",
      "Uploaded data/data_for_batch_inference/65, 63 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/94\n",
      "Uploaded data/data_for_batch_inference/66, 64 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/95\n",
      "Uploaded data/data_for_batch_inference/67, 65 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/96\n",
      "Uploaded data/data_for_batch_inference/68, 66 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/97\n",
      "Uploaded data/data_for_batch_inference/69, 67 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/98\n",
      "Uploaded data/data_for_batch_inference/7, 68 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/99\n",
      "Uploaded data/data_for_batch_inference/70, 69 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/71, 70 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/72, 71 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/73, 72 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/74, 73 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/75, 74 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/76, 75 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/77, 76 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/78, 77 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/79, 78 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/8, 79 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/80, 80 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/81, 81 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/82, 82 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/83, 83 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/84, 84 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/85, 85 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/86, 86 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/87, 87 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/88, 88 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/89, 89 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/9, 90 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/90, 91 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/91, 92 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/92, 93 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/93, 94 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/94, 95 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/95, 96 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/96, 97 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/97, 98 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/98, 99 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/99, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n"
     ]
    }
   ],
   "source": [
    "# upload files onto path_on_datastore to a blob container\n",
    "# our files are in the directory of 'path_on_datastore' in the blob container\n",
    "path_on_datastore = 'data_for_batch_inference'\n",
    "datastore = Datastore.get(workspace=workspace, datastore_name='workspaceblobstore')\n",
    "datastore.upload(src_dir='data/data_for_batch_inference', target_path=path_on_datastore, overwrite=True, show_progress=True)\n",
    "\n",
    "# get the DataPath object associated with the uploaded dataset\n",
    "datastore_path = [DataPath(datastore=datastore, path_on_datastore=path_on_datastore)]\n",
    "\n",
    "# dataset used as the input of the batch inference\n",
    "dataset = Dataset.File.from_files(path=datastore_path).as_named_input('dataset_for_batch_inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register an anonymous module from yaml file to the workspace\n",
    "If you decorate your module function with ```@dsl.module```, azure-cli-ml could help to generate the ```*.spec.yaml``` file.\n",
    "Please refer to the customized modules for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasttext_score_module_func = Module.from_yaml(workspace, 'fasttext_score/fasttext_score.spec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained fastText model from a complete experiment\n",
    "- get all experiments\n",
    "- choose an experiment from all experiments\n",
    "- get the latest run\n",
    "- get a PipelineRun associated with the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample10',\n",
       " 'sample5',\n",
       " 'sample5-realtime',\n",
       " 'simple10-batch',\n",
       " 'pythonscript',\n",
       " 'Data_dependency',\n",
       " 'clement',\n",
       " 'new_module',\n",
       " 'test_module2',\n",
       " 'test_m',\n",
       " 'module_SDK_local_module_test',\n",
       " 'fasttext_pipeline',\n",
       " 'fasttext_batch_inference',\n",
       " 'fasttext_pipeline2',\n",
       " 'fasttext_pipeline_endpoint',\n",
       " 'split_data_txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name_list = [exp.name for exp in Experiment.list(workspace)]\n",
    "exp_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment you want with its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>DesignerDRI_EASTUS</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: fasttext_pipeline,\n",
       "Workspace: DesignerDRI_EASTUS)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"fasttext_pipeline\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>93878b6e-4648-45d2-9123-d648d14e3872</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/93878b6e-4648-45d2-9123-d648d14e3872?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 93878b6e-4648-45d2-9123-d648d14e3872,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# azureml.pipeline.core.run.PipelineRun\n",
    "run = Run.list(experiment, status='Completed').__next__()\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a PipelineRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>93878b6e-4648-45d2-9123-d648d14e3872</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/93878b6e-4648-45d2-9123-d648d14e3872?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 93878b6e-4648-45d2-9123-d648d14e3872,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = run.id\n",
    "# azureml.pipeline.wrapper._pipeline_run.PipelineRun\n",
    "pipeline_run = PipelineRun(experiment, run_id)\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline so as to obtain information about the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51507703c004509974767aca071de40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_7268a475-2dd4-4cfc-9785-10452a05a9f3_widget', env_json='{}', graph_jsoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_7268a475-2dd4-4cfc-9785-10452a05a9f3_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_7268a475-2dd4-4cfc-9785-10452a05a9f3_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"7268a475-2dd4-4cfc-9785-10452a05a9f3\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"7268a475-2dd4-4cfc-9785-10452a05a9f3\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_7268a475-2dd4-4cfc-9785-10452a05a9f3_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"fasttext_pipeline\", \"data_references\": {\"THUCNews\": {\"dataset_id\": \"efa8f18c-9b9b-47f3-9630-de9002dc61aa\"}}, \"steps\": {\"5e18c1fd\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"5e18c1fd_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"5e18c1fd_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"5e18c1fd_Test_data_output\"}}, \"module\": {\"id\": \"c20fc3b7-e7bb-4013-b910-0f266e8efc2a\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"c20fc3b7-e7bb-4013-b910-0f266e8efc2a\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"69283a70\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"5e18c1fd_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"5e18c1fd_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"69283a70_Trained_model_dir\"}}, \"module\": {\"id\": \"076923cc-0acf-41ce-bfc7-69a7df690999\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"076923cc-0acf-41ce-bfc7-69a7df690999\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"60e02929\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"69283a70_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"5e18c1fd_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"60e02929_Model_testing_result\"}}, \"module\": {\"id\": \"3f148fa6-0484-4326-a53f-713032937824\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"3f148fa6-0484-4326-a53f-713032937824\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"389e3388\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"389e3388_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"389e3388_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"389e3388_Test_data_output\"}}, \"module\": {\"id\": \"c20fc3b7-e7bb-4013-b910-0f266e8efc2a\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"c20fc3b7-e7bb-4013-b910-0f266e8efc2a\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"850277f1\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"389e3388_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"389e3388_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"850277f1_Trained_model_dir\"}}, \"module\": {\"id\": \"076923cc-0acf-41ce-bfc7-69a7df690999\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"076923cc-0acf-41ce-bfc7-69a7df690999\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"fbe4b367\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"850277f1_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"389e3388_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"fbe4b367_Model_testing_result\"}}, \"module\": {\"id\": \"3f148fa6-0484-4326-a53f-713032937824\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"3f148fa6-0484-4326-a53f-713032937824\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"98b9cfe8\": {\"inputs\": {\"First_trained_model\": {\"source\": \"69283a70_Trained_model_dir\"}, \"First_trained_result\": {\"source\": \"60e02929_Model_testing_result\"}, \"Second_trained_model\": {\"source\": \"850277f1_Trained_model_dir\"}, \"Second_trained_result\": {\"source\": \"fbe4b367_Model_testing_result\"}}, \"outputs\": {}, \"module\": {\"id\": \"02f212ec-9e56-4dba-8481-0918c9c10a4e\", \"version\": \"0.0.18\"}, \"validate\": {\"error\": [], \"module_id\": \"02f212ec-9e56-4dba-8481-0918c9c10a4e\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Compare Two Models\", \"module_version\": \"0.0.18\"}}}}, \"modules\": [{\"module_id\": \"c20fc3b7-e7bb-4013-b910-0f266e8efc2a\", \"version\": \"0.0.43\", \"name\": \"Split Data Txt\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dir\", \"label\": \"Input dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Training_data_output\", \"label\": \"Training data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Validation_data_output\", \"label\": \"Validation data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Test_data_output\", \"label\": \"Test data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"076923cc-0acf-41ce-bfc7-69a7df690999\", \"version\": \"0.0.41\", \"name\": \"FastText Train\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Training_data_dir\", \"label\": \"Training data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Validation_data_dir\", \"label\": \"Validation data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_id\": \"ModelDirectory\"}]}}, {\"module_id\": \"3f148fa6-0484-4326-a53f-713032937824\", \"version\": \"0.0.8\", \"name\": \"FastText Evaluation\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Test_data_dir\", \"label\": \"Test data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Model_testing_result\", \"label\": \"Model testing result\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"02f212ec-9e56-4dba-8481-0918c9c10a4e\", \"version\": \"0.0.18\", \"name\": \"Compare Two Models\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"First_trained_model\", \"label\": \"First trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"First_trained_result\", \"label\": \"First trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_model\", \"label\": \"Second trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_result\", \"label\": \"Second trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"The_better_model\", \"label\": \"The better model\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [{\"name\": \"THUCNews\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data     of Sina News RSS subscription channel from 2005 to 2011\", \"version\": \"1\", \"registered_id\": \"efa8f18c-9b9b-47f3-9630-de9002dc61aa\", \"saved_id\": \"8ece8ea8-1318-4d4d-8cac-2acb631feb85\", \"nodeId\": \"70286d9a-c269-31a9-bbba-13fbf3d37b70\"}], \"subGraphInfo\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"e863cc03-4b84-48ab-a173-6e261714009e\", \"pipeline_definition_id\": \"50a9a7c6-5b33-48a5-a685-2984f5b2e5ca\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"98b9cfe8\"], \"sub_graph_default_data_store_nodes\": [\"98b9cfe8\"], \"inputs\": [], \"outputs\": []}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"e142a411-5100-41db-830e-14266f9e70e2\", \"parent_graph_id\": \"e863cc03-4b84-48ab-a173-6e261714009e\", \"pipeline_definition_id\": \"72ddc002-15bc-435c-859c-3ceb46e7da06\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"69283a70\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"69283a70\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"69283a70\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"5e18c1fd\", \"69283a70\", \"60e02929\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"60e02929\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"98b9cfe8\", \"port_name\": \"First_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"69283a70\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"60e02929\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"98b9cfe8\", \"port_name\": \"First_trained_model\"}]}]}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"47a08e22-904a-444f-8d53-07f20d3447cf\", \"parent_graph_id\": \"e863cc03-4b84-48ab-a173-6e261714009e\", \"pipeline_definition_id\": \"72ddc002-15bc-435c-859c-3ceb46e7da06\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"850277f1\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"850277f1\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"850277f1\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"389e3388\", \"850277f1\", \"fbe4b367\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"fbe4b367\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"98b9cfe8\", \"port_name\": \"Second_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"850277f1\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"fbe4b367\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"98b9cfe8\", \"port_name\": \"Second_trained_model\"}]}]}], \"nodeIdToSubGraphIdMapping\": {\"5e18c1fd\": \"e142a411-5100-41db-830e-14266f9e70e2\", \"69283a70\": \"e142a411-5100-41db-830e-14266f9e70e2\", \"60e02929\": \"e142a411-5100-41db-830e-14266f9e70e2\", \"389e3388\": \"47a08e22-904a-444f-8d53-07f20d3447cf\", \"850277f1\": \"47a08e22-904a-444f-8d53-07f20d3447cf\", \"fbe4b367\": \"47a08e22-904a-444f-8d53-07f20d3447cf\", \"98b9cfe8\": \"e863cc03-4b84-48ab-a173-6e261714009e\"}, \"subPipelineDefinition\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"fasttext_pipeline\", \"id\": \"50a9a7c6-5b33-48a5-a685-2984f5b2e5ca\", \"from_module_name\": \"__main__\", \"parameter_list\": []}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"72ddc002-15bc-435c-859c-3ceb46e7da06\", \"from_module_name\": \"__main__\", \"parameter_list\": [{\"key\": \"epochs\"}, {\"key\": \"batch_size\"}, {\"key\": \"max_len\"}]}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_7268a475-2dd4-4cfc-9785-10452a05a9f3_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_run.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get a StepRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>a1b098d2-3352-4974-8155-abb1835258d3</td><td>azureml.StepRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/a1b098d2-3352-4974-8155-abb1835258d3?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "StepRun(Experiment: fasttext_pipeline,\n",
       "Id: a1b098d2-3352-4974-8155-abb1835258d3,\n",
       "Type: azureml.StepRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain step_run_id from the visualization result.\n",
    "step_run_id = 'a1b098d2-3352-4974-8155-abb1835258d3'\n",
    "step_run = pipeline_run.get_step_run(step_run_id)\n",
    "step_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to use the trained model from a port without registration, we need to install an extra dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://azuremlsdktestpypi.azureedge.net/modulesdkpreview\n",
      "Requirement already up-to-date: azureml-dataset-runtime[fuse] in /home/azureuser/.local/lib/python3.6/site-packages (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: azureml-dataprep<2.1.0a,>=2.0.1a in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (2.0.3a2020080602)\n",
      "Requirement already satisfied, skipping upgrade: pyarrow<2.0.0,>=0.17.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: fusepy<4.0.0,>=3.0.1; extra == \"fuse\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: azureml-dataprep-native<21.0.0,>=20.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (20.0.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-identity<1.3.0,>=1.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle<2.0.0,>=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: dotnetcore2<3.0.0,>=2.1.14 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.1.14)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pyarrow<2.0.0,>=0.17.0->azureml-dataset-runtime[fuse]) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: msal-extensions~=0.1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (0.1.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-core<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.1.4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.9.2)\n",
      "Requirement already satisfied, skipping upgrade: msal<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: distro>=1.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from dotnetcore2<3.0.0,>=2.1.14->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: portalocker~=1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msal-extensions~=0.1.3->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.18.4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-core<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography>=2.1.4->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT[crypto]<2,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# Install dataset runtime to enable dataset registration in sample notebooks\n",
    "!pip install azureml-dataset-runtime[fuse] --extra-index-url https://azuremlsdktestpypi.azureedge.net/modulesdkpreview --user --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use the trained model as the input of a new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig at 0x7f539c4beba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = step_run.get_port(name='The_better_model')\n",
    "data_path = port.get_data_path()\n",
    "model = Dataset.File.from_files(path=[data_path]).as_named_input('model_for_batch_inference')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='batch inference', description='Batch Inference', default_compute_target=aml_compute.name)\n",
    "def training_pipeline(dataset=dataset, model=model):\n",
    "    fasttext_score = fasttext_score_module_func(\n",
    "        texts_to_score=dataset,\n",
    "        fasttext_model_dir=model\n",
    "    )\n",
    "    fasttext_score.runsettings.configure(node_count=2, process_count_per_node=2, mini_batch_size=\"64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.pipeline.wrapper._pipeline.Pipeline at 0x7f539c06d668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipeline = training_pipeline()\n",
    "# pipeline.save(experiment_name=experiment_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 890cf5de-8037-40cc-859d-215a7a2921e0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_batch_inference/runs/890cf5de-8037-40cc-859d-215a7a2921e0?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\n",
      "PipelineRunId: 890cf5de-8037-40cc-859d-215a7a2921e0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_batch_inference/runs/890cf5de-8037-40cc-859d-215a7a2921e0?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2b5316302b4a5c84f3c1978848de21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_8f2f4246-9ae0-482a-8844-3a24cef107e9_widget', env_json='{}', graph_jsoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_8f2f4246-9ae0-482a-8844-3a24cef107e9_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_8f2f4246-9ae0-482a-8844-3a24cef107e9_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"8f2f4246-9ae0-482a-8844-3a24cef107e9\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"8f2f4246-9ae0-482a-8844-3a24cef107e9\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_8f2f4246-9ae0-482a-8844-3a24cef107e9_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"batch inference\", \"data_references\": {\"dataset\": {\"saved_id\": \"11f0a26b-d865-4ad4-8c9e-6fe79aedbcc9\"}, \"model\": {\"saved_id\": \"0fb7e537-b666-44e3-ad28-531504dac921\"}}, \"steps\": {\"da9010f9\": {\"inputs\": {\"Texts_to_score\": {\"source\": \"dataset\"}, \"Fasttext_model_dir\": {\"source\": \"model\"}}, \"outputs\": {}, \"module\": {\"id\": \"326bb321-8675-4609-837c-68bdcb17121f\", \"version\": \"0.0.23\"}, \"validate\": {\"error\": [], \"module_id\": \"326bb321-8675-4609-837c-68bdcb17121f\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Score\", \"module_version\": \"0.0.23\"}}}}, \"modules\": [{\"module_id\": \"326bb321-8675-4609-837c-68bdcb17121f\", \"version\": \"0.0.23\", \"name\": \"FastText Score\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Texts_to_score\", \"label\": \"Texts to score\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Fasttext_model_dir\", \"label\": \"Fasttext model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Scored_data_output_dir\", \"label\": \"Scored data output dir\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [], \"subGraphInfo\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"be6aaca5-e9a9-4fe8-94a2-a23987c8cde9\", \"pipeline_definition_id\": \"26643988-34e8-42b2-a2c0-70a99f3d2f4c\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"da9010f9\"], \"sub_graph_default_data_store_nodes\": [\"da9010f9\"], \"inputs\": [{\"name\": \"dataset\", \"internal\": [{\"node_id\": \"da9010f9\", \"port_name\": \"Texts_to_score\"}], \"external\": []}, {\"name\": \"model\", \"internal\": [{\"node_id\": \"da9010f9\", \"port_name\": \"Fasttext_model_dir\"}], \"external\": []}], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"da9010f9\": \"be6aaca5-e9a9-4fe8-94a2-a23987c8cde9\"}, \"subPipelineDefinition\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"26643988-34e8-42b2-a2c0-70a99f3d2f4c\", \"from_module_name\": \"__main__\", \"parameter_list\": [{\"key\": \"dataset\", \"value\": \"<azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x7f539cd137f0>\"}, {\"key\": \"model\", \"value\": \"<azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x7f539c4beba8>\"}]}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_8f2f4246-9ae0-482a-8844-3a24cef107e9_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<RunStatus.completed: 'Completed'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline_run\n",
    "experiment_name = 'fasttext_batch_inference'\n",
    "pipeline_run = pipeline.submit(experiment_name=experiment_name, regenerate_outputs=False)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download results of batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_batch_inference</td><td>710b6bd4-e3bc-4cbc-82e5-f1569d303b87</td><td>azureml.StepRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_batch_inference/runs/710b6bd4-e3bc-4cbc-82e5-f1569d303b87?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "StepRun(Experiment: fasttext_batch_inference,\n",
       "Id: 710b6bd4-e3bc-4cbc-82e5-f1569d303b87,\n",
       "Type: azureml.StepRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_run_id = '710b6bd4-e3bc-4cbc-82e5-f1569d303b87'\n",
    "step_run = pipeline_run.get_step_run(step_run_id)\n",
    "step_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/136e879ec35445efaa8c140e75934fee.parquet\n",
      "Downloading azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/88e6e74d1e104869a04ea0b7792025f1.parquet\n",
      "Downloading azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/a2f5344ac5f642dbb5620d6821c7cffd.parquet\n",
      "Downloading azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/c6028b5a23194c7ca8eb35dfbd1496f0.parquet\n",
      "Downloaded azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/136e879ec35445efaa8c140e75934fee.parquet, 1 files out of an estimated total of 4\n",
      "Downloaded azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/a2f5344ac5f642dbb5620d6821c7cffd.parquet, 2 files out of an estimated total of 4\n",
      "Downloaded azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/88e6e74d1e104869a04ea0b7792025f1.parquet, 3 files out of an estimated total of 4\n",
      "Downloaded azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir/c6028b5a23194c7ca8eb35dfbd1496f0.parquet, 4 files out of an estimated total of 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/azureml/710b6bd4-e3bc-4cbc-82e5-f1569d303b87/Scored_data_output_dir'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = step_run.get_port(name='Scored data output dir')\n",
    "saved_path = port.download(overwrite=True)\n",
    "saved_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the results of batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tmp/tmp9rblqy76/0</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tmp/tmp9rblqy76/1</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tmp/tmp9rblqy76/10</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tmp/tmp9rblqy76/100</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tmp/tmp9rblqy76/101</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/tmp/tmp9rblqy76/102</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/tmp/tmp9rblqy76/103</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/tmp/tmp9rblqy76/104</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/tmp/tmp9rblqy76/105</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/tmp/tmp9rblqy76/106</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename          Class\n",
       "0    /tmp/tmp9rblqy76/0  entertainment\n",
       "1    /tmp/tmp9rblqy76/1      education\n",
       "2   /tmp/tmp9rblqy76/10        finance\n",
       "3  /tmp/tmp9rblqy76/100           game\n",
       "4  /tmp/tmp9rblqy76/101      education\n",
       "5  /tmp/tmp9rblqy76/102        society\n",
       "6  /tmp/tmp9rblqy76/103           game\n",
       "7  /tmp/tmp9rblqy76/104      education\n",
       "8  /tmp/tmp9rblqy76/105  entertainment\n",
       "9  /tmp/tmp9rblqy76/106           game"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for i, file in enumerate(os.listdir(saved_path)):\n",
    "    path = os.path.join(saved_path, file)\n",
    "    df_list.append(pd.read_parquet(path, engine='pyarrow'))\n",
    "df = pd.concat(df_list) \n",
    "print(df.shape)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse this pipeline with PipelineEndpoint\n",
    "Suppose you need to do batch inference for a new dataset. Just reuse this pipeline with PipelineEndpoint.\n",
    "\n",
    "Suppose you want to choose a new model to do batch inference. Just reuse this pipeline with PipelineEndpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline endpoint\n",
    "Publish the above pipeline to a pipeline endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Description</th><th>Date updated</th><th>Updated by</th><th>Last run time</th><th>Last run status</th><th>Status</th><th>tags</th><th>Portal Link</th></tr><tr><td>fasttext_endpoint</td><td></td><td>2020-08-18 09:37:10.713346+00:00</td><td>Xiaoyu Yang</td><td>2020-08-18 03:42:13.750136+00:00</td><td>Unknown</td><td>Unknown</td><td>azureml.Designer: true</td><td><a href=\"https://ml.azure.com/endpoint/a9aa25a4-3944-44c7-a34e-4949d0a06948/fasttext_endpoint/pipelines?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineEndpoint(Name: fasttext_endpoint,\n",
       "Description: None,\n",
       "Date updated: 2020-08-18 09:37:10.713346+00:00,\n",
       "Updated by: Xiaoyu Yang,\n",
       "Last run time: 2020-08-18 03:42:13.750136+00:00,\n",
       "Last run status: Unknown,\n",
       "Status: Unknown,\n",
       "tags: azureml.Designer: true,\n",
       "Portal Link: https://ml.azure.com/endpoint/a9aa25a4-3944-44c7-a34e-4949d0a06948/fasttext_endpoint/pipelines?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'fasttext_endpoint'\n",
    "try:\n",
    "    pipeline_endpoint = PipelineEndpoint.get(workspace=workspace, name=name)\n",
    "except:\n",
    "    # If there exists a pipeline endpoint, publish the above pipeline to a pipeline endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.publish(workspace=workspace, name=name, pipeline=pipeline_run)\n",
    "pipeline_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a new dataset\n",
    "Here, we use the dataset we used just now. To make a difference, we give it a new module name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig at 0x7f537c2c5b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.File.from_files(path=datastore_path).as_named_input('dataset_for_batch_inference_new')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a new model\n",
    "Here, we use the model used just now. To make a difference, we give it a new module name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig at 0x7f537c1d3a20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dataset.File.from_files(path=[data_path]).as_named_input('model_for_batch_inference_new')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a pipeline experiment through pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineEndpointRun ead49c22-3621-4a2f-adde-49a789c3d9ce\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_pipeline_endpoint/runs/ead49c22-3621-4a2f-adde-49a789c3d9ce?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\n",
      "PipelineRunId: ead49c22-3621-4a2f-adde-49a789c3d9ce\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_pipeline_endpoint/runs/ead49c22-3621-4a2f-adde-49a789c3d9ce?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a409baba6a418985214720c3d225f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_e86065ce-962e-411b-aded-520dd9a12898_widget', env_json='{}', graph_jsoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_e86065ce-962e-411b-aded-520dd9a12898_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_e86065ce-962e-411b-aded-520dd9a12898_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"e86065ce-962e-411b-aded-520dd9a12898\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"e86065ce-962e-411b-aded-520dd9a12898\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_e86065ce-962e-411b-aded-520dd9a12898_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"batch inference\", \"data_references\": {\"11f0a26b-d865-4ad4-8c9e-6fe79aedbcc9\": {\"saved_id\": \"11f0a26b-d865-4ad4-8c9e-6fe79aedbcc9\"}, \"0fb7e537-b666-44e3-ad28-531504dac921\": {\"saved_id\": \"0fb7e537-b666-44e3-ad28-531504dac921\"}}, \"steps\": {\"8bb699df\": {\"inputs\": {\"Texts_to_score\": {\"source\": \"11f0a26b-d865-4ad4-8c9e-6fe79aedbcc9\"}, \"Fasttext_model_dir\": {\"source\": \"0fb7e537-b666-44e3-ad28-531504dac921\"}}, \"outputs\": {}, \"module\": {\"id\": \"1a2ea483-4e54-4aea-84eb-4c9a681cda4c\", \"version\": \"0.0.23\"}, \"validate\": {\"error\": [], \"module_id\": \"1a2ea483-4e54-4aea-84eb-4c9a681cda4c\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Score\", \"module_version\": \"0.0.23\"}}}}, \"modules\": [{\"module_id\": \"1a2ea483-4e54-4aea-84eb-4c9a681cda4c\", \"version\": \"0.0.23\", \"name\": \"FastText Score\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Texts_to_score\", \"label\": \"Texts to score\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Fasttext_model_dir\", \"label\": \"Fasttext model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Scored_data_output_dir\", \"label\": \"Scored data output dir\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [], \"subGraphInfo\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"9cea89ae-e928-4a1c-b54c-0c3325b7410d\", \"pipeline_definition_id\": \"e9aa6268-87cf-4c5a-a83d-0529db5a886b\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"8bb699df\"], \"sub_graph_default_data_store_nodes\": [\"8bb699df\"], \"inputs\": [], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"8bb699df\": \"9cea89ae-e928-4a1c-b54c-0c3325b7410d\"}, \"subPipelineDefinition\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"e9aa6268-87cf-4c5a-a83d-0529db5a886b\", \"from_module_name\": \"__main__\", \"parameter_list\": []}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_e86065ce-962e-411b-aded-520dd9a12898_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<RunStatus.completed: 'Completed'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'fasttext_pipeline_endpoint'\n",
    "pipeline_run = pipeline_endpoint.submit(experiment_name=experiment_name, parameters={'dataset':dataset, 'model':model})\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttext",
   "language": "python",
   "name": "fasttext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
